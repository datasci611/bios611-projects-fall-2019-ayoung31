{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "client_df = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/CLIENT_191102.tsv\", sep='\\t')\n",
    "dis_enter = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/DISABILITY_ENTRY_191102.tsv\", sep='\\t')\n",
    "dis_exit = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/DISABILITY_EXIT_191102.tsv\", sep='\\t')\n",
    "ee_reviews = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/EE_REVIEWS_191102.tsv\", sep='\\t')\n",
    "ee_udes = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/EE_UDES_191102.tsv\", sep='\\t')\n",
    "entry_exit = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/ENTRY_EXIT_191102.tsv\", sep='\\t')\n",
    "health_ins_entry = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/HEALTH_INS_ENTRY_191102.tsv\", sep='\\t')\n",
    "health_ins_exit = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/HEALTH_INS_EXIT_191102.tsv\", sep='\\t')\n",
    "income_entry = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/INCOME_ENTRY_191102.tsv\", sep='\\t')\n",
    "income_exit = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/INCOME_EXIT_191102.tsv\", sep='\\t')\n",
    "noncash_entry = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/NONCASH_ENTRY_191102.tsv\", sep='\\t')\n",
    "noncash_exit = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/NONCASH_EXIT_191102.tsv\", sep='\\t')\n",
    "fam = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/VI_SPDAT_FAM_V2_191102.tsv\", sep='\\t')\n",
    "ind = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/VI_SPDAT_IND_V2_191102.tsv\", sep='\\t')\n",
    "v1 = pd.read_csv(\"https://raw.githubusercontent.com/biodatascience/datasci611/gh-pages/data/project2_2019/VI_SPDAT_V1_191102.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure Disability dataset so that it can be merged with others\n",
    "temp = dis_enter[['EE UID','Disability Determination (Entry)','Disability Type (Entry)']]\n",
    "temp = temp.drop_duplicates()\n",
    "temp2 = temp.pivot_table(index=['EE UID'],\n",
    "                             columns=['Disability Type (Entry)'],\n",
    "                             values=['Disability Determination (Entry)'],\n",
    "                             aggfunc=lambda x: ' '.join(str(v) for v in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amyou\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:617: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Merge all datasets of interest\n",
    "df = client_df.merge(entry_exit, on='EE UID', how='inner').merge(ee_udes, on=\"EE UID\", how='inner').merge(temp2, on=\"EE UID\", how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1st column\n",
    "df = df.iloc[:,1:59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove other columns that are either duplicates or not of interest\n",
    "df = df.drop(['Client Unique ID_x', 'EE Provider ID_y','Client ID_y','Client Unique ID_y','Entry Exit Group Id','Entry Exit Household Id','Unnamed: 6','Client Unique ID','Client ID','Zip Code (of Last Permanent Address, if known)(1932)','Relationship to Head of Household(4374)','If yes for Domestic violence victim/survivor, when experience occurred(1917)','Date of Birth(893)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all remaining columns\n",
    "df.columns = ['EE_UID', \"Client_ID\", \"Age_Entry\", \"Age_Exit\", \"Gender\", \"Race\", \"Ethnicity\", \"Veteran\", \"Entry_Date\", \"MoveIn_Date\", \"Exit_Date\", \"Destination\", \"Reason_for_Leaving\", \"EE_Type\", \"remove1\", \"remove2\", \"remove3\", \"remove4\", \"remove5\", \"Prior_Living\", \"Length_at_Prior\", \"Less_7days\", \"Less_90days\", \"streetsESSH_night_before\", \"times_street_ESSH_past3yrs_includetoday\", \"month_homeless_streetESSH_past3yrs\", \"Housing_Status\", \"Disabling_Condition\", \"Health_Ins\", \"Dom_Violence\", \"Alc_Abuse\", \"DrugAndAlc_Abuse\", \"Chronic_Health_Cond\", \"Devel_Disability\", \"Drug_Abuse\", \"Dual_Diagnosis\", \"HIV_AIDS\", \"Hearing_Impaired\", \"Mental_Health\", \"Other\", \"Learning\", \"Speech\", \"Physical\", \"Physical_Medical\", \"Visual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to date/time variable types\n",
    "df['Date_Enter'] = pd.to_datetime(df[\"Entry_Date\"], format=\"%m/%d/%Y\")\n",
    "df['Date_Exit'] = pd.to_datetime(df[\"Exit_Date\"], format=\"%m/%d/%Y\")\n",
    "df['days_at_shelter'] = (df['Date_Exit'] - df['Date_Enter']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a few more columns I don't need\n",
    "df = df.drop(['remove1', 'remove2', 'remove3', 'remove4', 'remove5', 'EE_UID','Entry_Date','Exit_Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as csv\n",
    "df.to_csv(\"../data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
